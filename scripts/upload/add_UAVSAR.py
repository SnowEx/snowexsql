"""
This script uploads the UAVSAR raster to the database after they have been
converted to geotifs.

Usage:
1. Download the data from the GDrive sent from HP.

2. Unzip into your Downloads.

3. Convert data to GeoTiffs, and reprojects it (use convert_uavsar.py)

4. Run this script.

Usage:
    # To run with all the scripts
    python run.py

    # To run individually
    python add_UAVSAR.py

"""
import sys
import glob
from os.path import abspath, expanduser, join

from snowexsql.batch import UploadUAVSARBatch


def main():

    region = 'all'

    if len(sys.argv) > 1:
        region = sys.argv[1]

    # Location of the downloaded data
    downloads = '../download/data/uavsar'

    # Sub folder name under the downloaded data that the tifs were saved to
    geotif_loc = 'geotiffs'

    data = {
        # Tile the data going in for faster retrieval
        'tiled': True,

        # Spatial Reference
        'epsg': 26912,

        # Metadata
        'surveyors': 'UAVSAR team, JPL',
        'instrument': 'UAVSAR, L-band InSAR',
        'site_name': 'Grand Mesa',
        'units': None,  # Add from the Annotation file
        'description': '',  # Added from the annotation file
        'doi': "https://asf.alaska.edu/doi/uavsar/#R0ARICRBAKYE"
    }

    # Expand the paths
    downloads = abspath(expanduser(downloads))
    geotif_loc = join(downloads, geotif_loc)

    # error counting
    errors_count = 0

    if region in ['all', 'grand_mesa']:
        print('Uploading Grand Mesa')
        ########################## Grand Mesa #####################################
        # Grab all the grand mesa annotation files in the original data folder
        ann_files = glob.glob(join(downloads, 'grmesa_*.ann'))

        # Instantiate the uploader
        rs = UploadUAVSARBatch(ann_files, geotiff_dir=geotif_loc, **data)

        # Submit to the db
        rs.push()

        # Keep track of number of errors for run.py
        errors_count += len(rs.errors)

        # Memory clean up
        del rs

    # if region in ['all', 'lowman']:
    #     print('Uploading Lowman')
    #     ############################### Idaho - Lowman ####################################
    #     # Make adjustments to metadata for lowman files
    #     data['site_name'] = 'idaho'
    #     data['epsg'] = 29611
    #
    #     # Grab all the lowman and reynolds annotation files
    #     ann_files = glob.glob(join(downloads, 'lowman_*.ann'))
    #
    #     # Instantiate the uploader
    #     rs = UploadUAVSARBatch(ann_files, geotiff_dir=geotif_loc, **data)
    #
    #     # Submit to the db
    #     rs.push()
    #
    #     # Keep track of the number of errors
    #     errors_count += len(rs.errors)
    #
    #     # Memory clean up
    #     del rs
    #
    # if region in ['all', 'reynolds']:
    #     print("Uploading Reynolds Creek")

        ############################### Idaho - Reynolds ####################################
        # # Make adjustments to metadata for lowman files
        # data['site_name'] = 'idaho'
        # data['epsg'] = 29611
        #
        # # Grab all the lowman and reynolds annotation files
        # ann_files = glob.glob(join(downloads, 'silver_*.ann'))
        #
        # # Instantiate the uploader
        # rs = UploadUAVSARBatch(ann_files, geotiff_dir=geotif_loc, **data)
        #
        # # Submit to the db
        # rs.push()
        #
        # # Keep track of the number of errors
        # errors_count += len(rs.errors)
        #
        # # Return the error count so run.py can keep track
        # return errors_count


if __name__ == '__main__':
    main()
